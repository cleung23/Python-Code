{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c395336b-ad97-4684-b78a-ee8c5bca0e01",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "The following sample codes are examples of CNN and LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7b32f0-485b-4b8c-96c2-8a757315b3aa",
   "metadata": {},
   "source": [
    "## 1. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd616c1-72fa-4c4d-9481-fd6f1c8b3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train data to np array, reshape to 4 dimensional.\n",
    "from sklearn import preprocessing\n",
    "ActiveTran2 = preprocessing.normalize(ActiveTran1) #range 0-1\n",
    "ActiveTran2 = pd.DataFrame(ActiveTran2, columns = ActiveTran1.columns)\n",
    "ActiveTran3 = ActiveTran2.values\n",
    "\n",
    "tran = []\n",
    "for i in range(len(TrainLab)):\n",
    "    age = ActiveTran2.loc[i:i+5,['Age']]\n",
    "    tm = ActiveTran2.loc[i:i+5,['TenureMonth']]\n",
    "    s = ActiveTran2.loc[i:i + 5, ['NoOfSavingsP']]\n",
    "    l = ActiveTran2.loc[i:i + 5, ['NoOfLoans']]\n",
    "    dd = ActiveTran2.loc[i:i + 5, ['NumberofDirectDeposits']]\n",
    "    sd = ActiveTran2.loc[i:i + 5, ['SumofDirectDeposits']]\n",
    "    bp = ActiveTran2.loc[i:i + 5, ['NumberofBillPayTransactions']]\n",
    "    dc = ActiveTran2.loc[i:i + 5, ['NumberofDebitCardTransactions']]\n",
    "    ib = ActiveTran2.loc[i:i + 5, ['NumberofTransactionsConductedinBranch']]\n",
    "    fc = ActiveTran2.loc[i:i + 5, ['FEESCHARGED']]\n",
    "    sf = ActiveTran2.loc[i:i + 5, ['SUMofFEESCHARGED']]\n",
    "    tt = ActiveTran2.loc[i:i + 5, ['NumberofTotalTransactions']]\n",
    "    ol = ActiveTran2.loc[i:i + 5, ['OnlineTran']]\n",
    "    py = ActiveTran2.loc[i:i + 5, ['NumberofPayments']]\n",
    "    sp = ActiveTran2.loc[i:i + 5, ['SumofPaymentAmount']]\n",
    "    at = ActiveTran2.loc[i:i + 5, ['AllTran']]\n",
    "    a = np.vstack((age, tm, s, l, dd, sd, bp, dc, ib, fc, sf, tt, ol, py, sp, at))\n",
    "    a = a.tolist()\n",
    "    tran.append(a)\n",
    "TrainTran = np.array(tran)\n",
    "TrainTran = np.reshape(tran,(TrainTran.shape[0],16,6,1))\n",
    "\n",
    "#Convert Target to categorical\n",
    "from keras.utils.np_utils import to_categorical\n",
    "Y = TrainLab[['Loyalty']].values\n",
    "Y = to_categorical(Y,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41077742-2ac5-45d6-be92-d4f6f663c28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building CNN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "#K.set_image_data_format('channels_last')\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "#Define model architecture\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=(16, 6, 1)))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 1)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D((1,1), strides=(1,1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile model, use cost sensitive learning\n",
    "model.compile(loss=WeightedCategoricalCrossentropy(cost_matrix), optimizer='adam', metrics=[tf.keras.metrics.CategoricalCrossentropy()])\n",
    "\n",
    "\n",
    "#Fit model on training data\n",
    "model.fit(TrainTran1, Train_Y3a, batch_size=32, epochs = 100, verbose=2)\n",
    "\n",
    "#Evaluate model on test data\n",
    "score = model.evaluate(TestTran1, Test_Y, verbose=2) #accuracy = 0.4685 (1 dense layer)\n",
    "#0.4302 (without dropout 0.5), 0.4691 (with dropout 0.5), Add more conv2d layers 0.4681, add dropout layer 0.4731\n",
    "#Change batch size no difference\n",
    "\n",
    "history = model.fit(TrainTran1, Y, validation_data=(TestTran1, Test_Y), batch_size=32, epochs=50, verbose=2)\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a7943-cc21-4ca8-adb7-f103361c6c3a",
   "metadata": {},
   "source": [
    "## 2. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ceaac7-3fcc-4153-b394-00a99ccd3f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation, convert train data to 3 dimensional np array\n",
    "from sklearn import preprocessing\n",
    "ActiveTran2 = preprocessing.normalize(ActiveTran1) #range 0-1\n",
    "ActiveTran2 = pd.DataFrame(ActiveTran2, columns = ActiveTran1.columns)\n",
    "\n",
    "tran = []\n",
    "for i in range(len(TrainLab)):\n",
    "    age = ActiveTran2.loc[i:i+5,['Age']]\n",
    "    tm = ActiveTran2.loc[i:i+5,['TenureMonth']]\n",
    "    s = ActiveTran2.loc[i:i + 5, ['NoOfSavingsP']]\n",
    "    l = ActiveTran2.loc[i:i + 5, ['NoOfLoans']]\n",
    "    dd = ActiveTran2.loc[i:i + 5, ['NumberofDirectDeposits']]\n",
    "    sd = ActiveTran2.loc[i:i + 5, ['SumofDirectDeposits']]\n",
    "    bp = ActiveTran2.loc[i:i + 5, ['NumberofBillPayTransactions']]\n",
    "    dc = ActiveTran2.loc[i:i + 5, ['NumberofDebitCardTransactions']]\n",
    "    ib = ActiveTran2.loc[i:i + 5, ['NumberofTransactionsConductedinBranch']]\n",
    "    fc = ActiveTran2.loc[i:i + 5, ['FEESCHARGED']]\n",
    "    sf = ActiveTran2.loc[i:i + 5, ['SUMofFEESCHARGED']]\n",
    "    tt = ActiveTran2.loc[i:i + 5, ['NumberofTotalTransactions']]\n",
    "    ol = ActiveTran2.loc[i:i + 5, ['OnlineTran']]\n",
    "    py = ActiveTran2.loc[i:i + 5, ['NumberofPayments']]\n",
    "    sp = ActiveTran2.loc[i:i + 5, ['SumofPaymentAmount']]\n",
    "    at = ActiveTran2.loc[i:i + 5, ['AllTran']]\n",
    "    a = np.hstack((age, tm, s, l, dd, sd, bp, dc, ib, fc, sf, tt, ol, py, sp, at))\n",
    "    a = a.tolist()\n",
    "    tran.append(a)\n",
    "TrainTran = np.array(tran)\n",
    "TrainTranL = np.reshape(tran,(TrainTran.shape[0],6,16))\n",
    "\n",
    "#Convert Target to categorical\n",
    "from keras.utils.np_utils import to_categorical\n",
    "Test_Y3 = TestLab[['Loyalty1']].values\n",
    "Test_Y3 = to_categorical(Test_Y3,3)\n",
    "\n",
    "Train_Y3 = TrainLab[['Loyalty1']].values\n",
    "Train_Y3 = to_categorical(Train_Y3,3)\n",
    "Y_train = Train_Y3.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52cbe0d-8b71-40f8-962d-ef299661db66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building LSTM\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "import keras as K\n",
    "\n",
    "n_timesteps, n_features, n_outputs = TrainTranL.shape[1], TrainTranL.shape[2], Train_Y3.shape[1]\n",
    "\n",
    "verbose, epochs, batch_size = 2, 200, 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "#model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.CategoricalCrossentropy()])\n",
    "\n",
    "# fit network\n",
    "history = model.fit(TrainTranL, Train_Y3, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# evaluate model\n",
    "accuracy = model.evaluate(TestTranL, Test_Y3, batch_size=batch_size, verbose=2)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Result of 150 epochs similar result with 200 epoch\n",
    "rounded_predictions = model.predict_classes(TestTranL, batch_size=batch_size, verbose=verbose)\n",
    "rounded_labels=np.argmax(Test_Y3, axis=1)\n",
    "print(classification_report(rounded_labels, rounded_predictions))\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
