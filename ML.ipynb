{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cc4948f-31c6-4b22-b11f-f8eb65914411",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "The following notebook shows sample codes of logistic regression, random forest and XG Boost.  Cross validation grid search is used in random forest and XG Boost to optimize the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73b84db-a265-44d6-8a91-f3314b7a99b3",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e481f-47e7-4278-968d-6ce86bdf5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da71d8-4f17-4c42-a766-41ff0ef5608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to get train scores\n",
    "def getTrainScores(gs):\n",
    "    results = {}\n",
    "    runs = 0\n",
    "    for x,y in zip(list(gs.cv_results_['mean_test_score']), gs.cv_results_['params']):\n",
    "        results[runs] = 'mean:' + str(x) + 'params' + str(y)\n",
    "        runs += 1\n",
    "    best = {'best_mean': gs.best_score_, \"best_param\":gs.best_params_}\n",
    "    return results, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ea6b5-4789-49fb-8867-49579c0b6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = LogisticRegression()\n",
    "# define the ovr strategy\n",
    "ovr = OneVsRestClassifier(model)\n",
    "# fit model\n",
    "ovr.fit(training_data['X_train'], training_data['Y_train'].reshape(training_data['Y_train'].shape[0],))\n",
    "# make predictions\n",
    "yhat = ovr.predict(training_data['X_test'])\n",
    "accuracy_score(training_data['Y_test'], yhat)\n",
    "confusion_matrix(training_data['Y_test'], yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9e19b-1af4-4437-a4d5-0085b61fd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = ovr.predict(training_data['X_train'])\n",
    "print('Train Accuracy:'+str(accuracy_score(training_data['Y_train'], train_pred)))\n",
    "print('Train F1-Score(Macro):'+str(f1_score(training_data['Y_train'], train_pred,average='macro')))\n",
    "print('------')\n",
    "print('Test Accuracy:'+str(accuracy_score(training_data['Y_test'], yhat))) \n",
    "print('Test F1-Score(Macro):'+str(f1_score(training_data['Y_test'], yhat,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5719a-4bb8-449c-9ced-d47b71e66f4c",
   "metadata": {},
   "source": [
    "## 2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e02bd2-65a1-4fab-99d5-328e84678986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_jobs=None,random_state=27, verbose=1)\n",
    "clf.fit(training_data['X_train'], training_data['Y_train'].reshape(training_data['Y_train'].shape[0],))\n",
    "predicted_labels = clf.predict(training_data['X_test'])\n",
    "accuracy_score(training_data['Y_test'], predicted_labels)\n",
    "train_pred = clf.predict(training_data['X_train'])\n",
    "\n",
    "print('Train Accuracy:'+str(accuracy_score(training_data['Y_train'], train_pred))) \n",
    "print('Train F1-Score(Macro):'+str(f1_score(training_data['Y_train'], train_pred,average='macro')))\n",
    "print('------')\n",
    "print('Test Accuracy:'+str(accuracy_score(training_data['Y_test'], predicted_labels))) \n",
    "print('Test F1-Score(Macro):'+str(f1_score(training_data['Y_test'], predicted_labels,average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d743655-7251-4715-8cc7-cffca57fad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV Search\n",
    "params = {\n",
    "    'n_estimators'      : [100, 500, 900],\n",
    "    'max_depth'         : [1, 5, 9],\n",
    "    'max_features': ['auto'],\n",
    "    'criterion' :['gini']\n",
    "}\n",
    "#metrics to consider: f1_micro, f1_macro, roc_auc_ovr\n",
    "gsearch1 = GridSearchCV(estimator = clf, param_grid = params, scoring='f1_micro',n_jobs=-1,verbose = 10, cv=10)\n",
    "gsearch1.fit(training_data['X_train'], training_data['Y_train'].reshape(training_data['Y_train'].shape[0],))\n",
    "\n",
    "gsearch1.best_estimator_ \n",
    "getTrainScores(gsearch1)\n",
    "predicted_labels = gsearch1.predict(training_data['X_test'])\n",
    "accuracy_score(training_data['Y_test'], predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c8e39-cb41-400c-8f77-e5fc7e4a0e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "features = TestSet5.columns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10,5))\n",
    "plot = sns.barplot(x=features, y=final_clf.feature_importances_)\n",
    "ax.set_title('Feature Importance')\n",
    "plot.set_xticklabels(plot.get_xticklabels(),rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe7093-de41-422a-9993-26fda9878697",
   "metadata": {},
   "source": [
    "## 3. XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8540b132-d184-477a-bc18-e10a381e0df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function displaying the results\n",
    "def fitXgb(sk_model, training_data=training_data, epochs=100):\n",
    "    sk_model.fit(training_data['X_train'], training_data['Y_train'].reshape(training_data['Y_train'].shape[0], ))\n",
    "    train = xgb.DMatrix(training_data['X_train'], label=training_data['Y_train'])\n",
    "    params = sk_model.get_xgb_params()\n",
    "    metrics = ['mlogloss', 'merror']\n",
    "    params['eval_metric'] = metrics\n",
    "    store = {}\n",
    "    evallist = [(train, 'train')]\n",
    "    xgb_model = xgb.train(params, train, epochs, evallist, evals_result=store, verbose_eval=100)\n",
    "    print('-- Model Report --')\n",
    "    print(\n",
    "        'XGBoost Accuracy: ' + str(accuracy_score(sk_model.predict(training_data['X_test']), training_data['Y_test'])))\n",
    "    print('XGBoost F1-Score (Macro): ' + str(\n",
    "        f1_score(sk_model.predict(training_data['X_test']), training_data['Y_test'], average='macro')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af477c4a-71c1-46d9-a762-fcd0c492771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost hyperparameter tuning with GridSearchCV\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "#initial model\n",
    "xgb1 = XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=100,\n",
    "                    max_depth=7,\n",
    "                    min_child_weight=7,\n",
    "                    gamma=0,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    objective='multi:softmax',\n",
    "                    nthread=4,\n",
    "                    num_class=9,\n",
    "                    seed=27)\n",
    "\n",
    "fitXgb(xgb1, training_data)\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':[1, 5, 9],\n",
    " 'min_child_weight':[1, 5, 9],\n",
    " 'n_estimators': range(100, 1000, 100)\n",
    "}\n",
    "#metrics to consider: f1_micro, f1_macro, roc_auc_ovr\n",
    "gsearch1 = GridSearchCV(estimator = xgb1, param_grid = param_test1, scoring='f1_macro',n_jobs=-1,verbose = 10, cv=3)\n",
    "gsearch1.fit(training_data['X_train'], training_data['Y_train'])\n",
    "\n",
    "getTrainScores(gsearch1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
